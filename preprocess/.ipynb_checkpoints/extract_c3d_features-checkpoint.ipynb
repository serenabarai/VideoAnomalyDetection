{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/BTP-SEM-7/vqa/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append('../') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Programs\\Anaconda3\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Programs\\Anaconda3\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Programs\\Anaconda3\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Programs\\Anaconda3\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Programs\\Anaconda3\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Programs\\Anaconda3\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'preprocess.array_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a112878f1c4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'preprocess.array_util'"
     ]
    }
   ],
   "source": [
    "from c3d.c3d import *\n",
    "import imageio\n",
    "from io import BytesIO\n",
    "from keras.utils import to_categorical,Sequence\n",
    "import numpy as np\n",
    "import os\n",
    "import parameters as params\n",
    "from utils.array_util import *\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_preprocess_image(archive, filename):\n",
    "    video = archive.read(filename)\n",
    "    vid = imageio.get_reader(BytesIO(video), 'ffmpeg')\n",
    "    frames=[]\n",
    "    for num, image in enumerate(vid.iter_data()): \n",
    "        frames.append(image)\n",
    "    # print(\"Shape of frames extracted\", np.array(frames).shape)\n",
    "    #Now shape of frames[] is [no of frames, 240, 320, 3]\n",
    "\n",
    "    #Before doing c3d preprocessing, we need to split this into clips of 16 frames each\n",
    "    clips = sliding_window(frames, params.frame_count, params.frame_count)\n",
    "    # print(\"Number of clips after sliding window\", len(clips))\n",
    "    # print(\"Shape of each clip after sliding window\", np.array(clips[0]).shape)\n",
    "    #shape of clips is (noOfFrames/16, 16, 240, 320, 3) \n",
    "\n",
    "    #Now we need to c3d preprocess each clip\n",
    "    preprocessed_clips=[]\n",
    "    for i, clip in enumerate(clips):\n",
    "        clip = np.array(clip)\n",
    "        if len(clip) < params.frame_count:   #for ignoring the last clip with less than 16frames\n",
    "            continue\n",
    "\n",
    "        clip = preprocess_input(clip)\n",
    "        preprocessed_clips.append(clip)\n",
    "        # print(\"Pre-processed clip : \", i)\n",
    "\n",
    "    # print(\"Shape after preprocessing\", np.array(preprocessed_clips).shape)\n",
    "    return np.array(preprocessed_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Image preloaded image features\n",
    "class My_Custom_Generator_Features(Sequence) :\n",
    "    def __init__(self,filenames, labels, batch_size, archive) :\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.archive = archive\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.filenames) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        print(\"index:\", idx)\n",
    "        batch_x = self.filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        #batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    \n",
    "        videos_x = np.empty((1,16,112,112,3))\n",
    "        for counter, video in enumerate(batch_x):\n",
    "            print(\"counter:\", counter)\n",
    "            op = extract_preprocess_image(self.archive, video)\n",
    "            print(op.shape)\n",
    "            videos_x = np.concatenate((videos_x, op), axis=0)\n",
    "    \n",
    "        batch_y = np.zeros((len(videos_x)-1, 4096))\n",
    "        return videos_x[1:], batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile('../../AnomalyVideos1.zip','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "fileNames=[]\n",
    "for name in archive.namelist():\n",
    "    if name.endswith('.mp4'):\n",
    "        fileNames.append(name)\n",
    "        name = name.split('/')\n",
    "        name = \"/\".join(name[1:])\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter: 0\n",
      "(86, 16, 112, 112, 3)\n",
      "counter: 1\n",
      "(112, 16, 112, 112, 3)\n",
      "counter: 2\n",
      "(320, 16, 112, 112, 3)\n",
      "counter: 3\n",
      "(170, 16, 112, 112, 3)\n",
      "counter: 4\n",
      "(213, 16, 112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "videos_x = np.empty((1,16,112,112,3))\n",
    "for counter, video in enumerate(fileNames[:5]):\n",
    "    print(\"counter:\", counter)\n",
    "    op = extract_preprocess_image(archive, video)\n",
    "    print(op.shape)\n",
    "    videos_x = np.concatenate((videos_x, op), axis=0)\n",
    "videos_x = videos_x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 16, 112, 112, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = c3d.predict(videos_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = int(np.ceil(len(fileNames)/batch_size))\n",
    "predictions = np.empty((1,4096))\n",
    "for i in range(0,batches):\n",
    "    batch_x = fileNames[i*batch_size:(i+1)*batch_size]\n",
    "    videos_x = np.empty((1,16,112,112,3))\n",
    "    for counter, video in enumerate(batch_x):\n",
    "        print(\"counter:\", counter)\n",
    "        op = extract_preprocess_image(archive, video)\n",
    "        print(op.shape)\n",
    "        videos_x = np.concatenate((videos_x, op), axis=0)\n",
    "    videos_x = videos_x[1:]\n",
    "    \n",
    "    pred = model.predict(videos_x)\n",
    "    predictions.concatenate((predictions,preds),axis=0)\n",
    "\n",
    "predictions = predictions[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(archive, batch_size=32):\n",
    "    c3d = c3d_feature_extractor()\n",
    "    names = []\n",
    "    fileNames=[]\n",
    "    for name in archive.namelist():\n",
    "        if name.endswith('.mp4'):\n",
    "            fileNames.append(name)\n",
    "            name = name.split('/')\n",
    "            name = \"/\".join(name[1:])\n",
    "            names.append(name)\n",
    "    \n",
    "    num_clips_video = []\n",
    "    fileNames = fileNames[:2]\n",
    "    batches = int(np.ceil(len(fileNames)/batch_size))\n",
    "    print(\"Batches:\", batches)\n",
    "    predictions = np.empty((1,4096))\n",
    "    for i in range(0,batches):\n",
    "        batch_x = fileNames[i*batch_size:(i+1)*batch_size]\n",
    "        videos_x = np.empty((1,16,112,112,3))\n",
    "        for counter, video in enumerate(batch_x):\n",
    "            print(\"counter:\", counter)\n",
    "            op = extract_preprocess_image(archive, video)\n",
    "            print(op.shape)\n",
    "            num_clips_video.append(op.shape[0])\n",
    "            videos_x = np.concatenate((videos_x, op), axis=0)\n",
    "        videos_x = videos_x[1:]\n",
    "\n",
    "        pred = c3d.predict(videos_x)\n",
    "        predictions.concatenate((predictions,preds),axis=0)\n",
    "\n",
    "    predictions = predictions[1:]\n",
    "    \n",
    "    return predictions, names, num_clips_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 1\n",
      "counter: 0\n",
      "(86, 16, 112, 112, 3)\n",
      "counter: 1\n",
      "(112, 16, 112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "getFeatures(archive,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(archive, batch_size=32):\n",
    "    c3d = c3d_feature_extractor()\n",
    "    names = []\n",
    "    fileNames=[]\n",
    "    for name in archive.namelist():\n",
    "        if name.endswith('.mp4'):\n",
    "            fileNames.append(name)\n",
    "            name = name.split('/')\n",
    "            name = \"/\".join(name[1:])\n",
    "            names.append(name)\n",
    "    predictions = np.empty((1,4096))\n",
    "    for counter, name in enumerate(fileNames):\n",
    "        print(\"counter:\",counter)\n",
    "        op = extract_preprocess_image(archive, name)\n",
    "        print(op.shape)\n",
    "        pred = c3d.predict(op)\n",
    "        predictions.concatenate((predictions,preds),axis=0)\n",
    "    return predictions[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
